{"cells":[{"cell_type":"markdown","id":"XI0O7B9La7n6","metadata":{"id":"XI0O7B9La7n6"},"source":["# Read me\n","1. To successfully run this code, one has to put all the folders downloaded from kaggle under the folder where this code is being run.\n","2. Ceate a folder called **path2** where all the pth files will be stored.\n","3. Run cells one after another to train and test the model\n","\n","## Model Description\n","* This is a model composed of 2 convolation layers, followed by one bi-directional lstm with 5 hidden layers and then two fully connected layers.\n","\n","* Details about the model structure is written in a text cell above the corresponding code cell.\n","\n","##Acknowledgement: \n","Most of the code is from hw3p2_bootcamp. I kinda just filled up the to-do section, and left almost everything else unchanged."]},{"cell_type":"markdown","id":"cypuxose-Q2y","metadata":{"id":"cypuxose-Q2y"},"source":["**You can skip the following 4 cells if everything has been properly installed.**"]},{"cell_type":"code","execution_count":null,"id":"ac1a689a-f2f7-4a9e-8e4b-373cb0eb4dbd","metadata":{"id":"ac1a689a-f2f7-4a9e-8e4b-373cb0eb4dbd"},"outputs":[],"source":["!kaggle competitions download -c 11785-homework-3-part-2-slack-seq-to-seq\n","!unzip 11785-homework-3-part-2-slack-seq-to-seq.zip"]},{"cell_type":"code","execution_count":null,"id":"7d8bf2a7-5aa4-4fb2-8553-6bbc0a51b165","metadata":{"id":"7d8bf2a7-5aa4-4fb2-8553-6bbc0a51b165"},"outputs":[],"source":["!git clone --recursive https://github.com/parlance/ctcdecode.git\n","!pip install wget\n","%cd ctcdecode\n","!pip install .\n","%cd .."]},{"cell_type":"code","execution_count":null,"id":"c0e88061-e055-4062-be2c-3de90be9bcbe","metadata":{"id":"c0e88061-e055-4062-be2c-3de90be9bcbe"},"outputs":[],"source":["!pip install python-Levenshtein"]},{"cell_type":"code","execution_count":null,"id":"35f5db72-40f8-47c9-b342-258363ffbe47","metadata":{"id":"35f5db72-40f8-47c9-b342-258363ffbe47"},"outputs":[],"source":["!pip install jupyter"]},{"cell_type":"markdown","id":"qfZ2LY8l-bYi","metadata":{"id":"qfZ2LY8l-bYi"},"source":["# **Starting From Here**"]},{"cell_type":"code","execution_count":null,"id":"481d26f3-f761-4fc6-9dc0-48449c5799c9","metadata":{"id":"481d26f3-f761-4fc6-9dc0-48449c5799c9","tags":[]},"outputs":[],"source":["import sys\n","import time\n","\n","import Levenshtein\n","\n","import numpy as np\n","import pandas as pd\n","\n","\n","import pdb\n","import gc\n","from tqdm.notebook import trange, tqdm\n","\n","import torch\n","import torch.nn as nn\n","\n","\n","from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence, pad_packed_sequence\n","from torch.utils.data import Dataset, DataLoader\n","import torch.optim as optim\n","\n","import warnings\n","warnings.filterwarnings('ignore')"]},{"cell_type":"code","execution_count":null,"id":"a04a8666-c82f-4af6-9408-3978de2b4bc3","metadata":{"id":"a04a8666-c82f-4af6-9408-3978de2b4bc3","outputId":"0bbfe29a-d231-4439-83e8-ee04835fa902"},"outputs":[{"name":"stdout","output_type":"stream","text":["Cuda =  True  with num_workers =  4\n"]}],"source":["# Check if cuda is available and set device\n","cuda = torch.cuda.is_available()\n","device = torch.device(\"cuda\" if cuda else \"cpu\")\n","\n","num_workers = 4 if cuda else 0\n","\n","print(\"Cuda = \", str(cuda), \" with num_workers = \", str(num_workers))"]},{"cell_type":"code","execution_count":null,"id":"de0801dd-6a31-4f5a-bf73-e08fe09d67bd","metadata":{"id":"de0801dd-6a31-4f5a-bf73-e08fe09d67bd"},"outputs":[],"source":["# load training and dev data\n","train_data = np.load('data/HW3P2_Data/train.npy', allow_pickle=True)\n","train_labels = np.load('data/HW3P2_Data/train_labels.npy', allow_pickle=True)\n","\n","dev_data = np.load('data/HW3P2_Data/dev.npy', allow_pickle=True)\n","dev_labels = np.load('data/HW3P2_Data/dev_labels.npy', allow_pickle=True)"]},{"cell_type":"markdown","id":"IG7pV-uhdc2f","metadata":{"id":"IG7pV-uhdc2f"},"source":["Run the following two cells to see the minimum lengths of labels.\n","\n","I used these as a guidance for determining the beam_width.\n","\n","\n","*(As far as I remembered, the minimum length of labels for both training data and validation data is 5, so I chose 3 as my beam_width)*"]},{"cell_type":"code","execution_count":null,"id":"5fe5e78b-d444-4f0d-aa76-a312c31b4b33","metadata":{"id":"5fe5e78b-d444-4f0d-aa76-a312c31b4b33"},"outputs":[],"source":["min([len(i) for i in train_labels])"]},{"cell_type":"code","execution_count":null,"id":"0f628ea0-932c-44b0-959d-5873e8c19ade","metadata":{"id":"0f628ea0-932c-44b0-959d-5873e8c19ade"},"outputs":[],"source":["min([len(i) for i in dev_labels])"]},{"cell_type":"markdown","id":"vgpvRZ-BeoxI","metadata":{"id":"vgpvRZ-BeoxI"},"source":["Note: I pre-permuted the padded x in the dataloader becuase pytorch's CNN expects input to be (N, C${_\\text{in}}$, L)"]},{"cell_type":"code","execution_count":null,"id":"840ade23-af78-4608-8443-6dfc6b0a6d2c","metadata":{"id":"840ade23-af78-4608-8443-6dfc6b0a6d2c"},"outputs":[],"source":["# Define dataset class\n","class MyDataSet(Dataset):\n","  # load the dataset\n","  def __init__(self, x, y):\n","    self.X = x\n","    self.Y = y\n","\n","  # get number of items/rows in dataset\n","  def __len__(self):\n","    return len(self.Y)\n","\n","  # get row item at some index\n","  def __getitem__(self, index):\n","    x = torch.FloatTensor(self.X[index])\n","    y = torch.LongTensor(self.Y[index])\n","\n","    return x, y\n","\n","  def collate_fn(batch):\n","    (x, y) = zip(*batch)\n","    x_lens = torch.as_tensor([len(xx) for xx in x])\n","    y_lens = torch.as_tensor([len(yy) for yy in y])\n","    x_pad = torch.as_tensor(pad_sequence(x, batch_first=True)).permute(0, 2, 1)#for CNN\n","    y_pad = torch.as_tensor(pad_sequence(y, batch_first=True))\n","    return x_pad, y_pad, x_lens, y_lens       "]},{"cell_type":"markdown","id":"Ec_SjQyvfYSH","metadata":{"id":"Ec_SjQyvfYSH"},"source":["I chose 64 because 128 and 80 both gave me **cuda out of memory error**."]},{"cell_type":"code","execution_count":null,"id":"fa881d79-bb3f-4dbc-8f02-e8b3c4ec36c8","metadata":{"id":"fa881d79-bb3f-4dbc-8f02-e8b3c4ec36c8"},"outputs":[],"source":["batch_size = 64 "]},{"cell_type":"code","execution_count":null,"id":"92c0bf7a-c34f-4117-a3d3-fface9602db5","metadata":{"id":"92c0bf7a-c34f-4117-a3d3-fface9602db5"},"outputs":[],"source":["\n","# training data\n","train = MyDataSet(train_data, train_labels)\n","train_args = {'batch_size': batch_size, \n","              'shuffle': True, 'num_workers': num_workers, \n","              'collate_fn': MyDataSet.collate_fn, 'pin_memory': True} # TODO: remember to use collate_fn\n","train_loader = DataLoader(train, **train_args)\n","\n","# validation data\n","dev = MyDataSet(dev_data, dev_labels)\n","dev_args = {'batch_size': batch_size, \n","            'shuffle': False, 'num_workers': num_workers, \n","            'collate_fn': MyDataSet.collate_fn, 'pin_memory': True}\n","dev_loader = DataLoader(dev, **dev_args)"]},{"cell_type":"markdown","id":"fCN0JRcyflM3","metadata":{"id":"fCN0JRcyflM3"},"source":["First, the input goes through convolution layer with kernel size  = 1, no padding, and stride = 1. \n","\n","I decided to start with kernel size = 1 because some forums, like [this one](https://news.ycombinator.com/item?id=17493492), mentioned that 1 by 1 kernel can be used as a pixel wise dense layer, which also acts like a nonlinear function to the neural network.\n","\n","Then I chose kernel_size  = 3, stride  = 1, padding  = 1 for the second convolution layer, simpy because I didn't want to alter the size of the original data.\n","\n","After two convolution layers, I added a drop out layer(p  = 0.5) because I noticed that my models (I have been trying with different models) always overfitted the trainning data, I decided to add a drop out layer to prevent overfitting.\n","\n","I permuted the x again for the input of lstm because it expects input with the size  = (N,L,H)\n","\n","Then, the input is packed and passed through bidirectional lstm with multiple hidden layers.\n","\n","Finally, I unpacked the data and passed it through 2 fully-connected layers with one dropout layer following the first activation layer of cnn, and passed the output through LogSoftmax to get probability."]},{"cell_type":"code","execution_count":null,"id":"2d929dfa-8168-4cd2-a5fb-9d32665b4da0","metadata":{"id":"2d929dfa-8168-4cd2-a5fb-9d32665b4da0"},"outputs":[],"source":["# TODO: Create model    \n","class LSTMModel(nn.Module):\n","  def __init__(self, input_size, hidden_size, num_layers, output_size):\n","    super(LSTMModel, self).__init__()\n","    self.input_size = input_size\n","    self.hidden_size = hidden_size\n","    self.num_layers = num_layers\n","    self.output_size = output_size\n","    #CNN\n","    self.conv1 = nn.Sequential(\n","        nn.Conv1d(input_size, hidden_size, kernel_size=1, stride=1, bias=False),\n","        nn.BatchNorm1d(hidden_size),\n","        nn.ELU(),)\n","    self.conv2 = nn.Sequential(\n","        nn.Conv1d(hidden_size, hidden_size, kernel_size=3, stride=1, padding=1, bias=False),\n","        nn.BatchNorm1d(hidden_size),\n","        nn.ELU(),)\n","    self.dropout = nn.Dropout()\n","    #lstm\n","    self.lstm = nn.LSTM(hidden_size, hidden_size, num_layers, batch_first=True, dropout=0.5, bidirectional=True)\n","    self.dense = nn.Sequential(\n","        nn.Linear(hidden_size*2, hidden_size),\n","        nn.ELU(),\n","        nn.Dropout(0.1),\n","        nn.Linear(hidden_size, output_size),)\n","    #softmax\n","    self.logsoftmax = nn.LogSoftmax(dim=2)\n","  def forward(self, x, lengths):     \n","    x = self.conv1(x)\n","    x = self.conv2(x)\n","    x = self.dropout(x)\n","    x = x.permute(0, 2, 1)\n","    x_pack = pack_padded_sequence(x, lengths.cpu(), batch_first=True, enforce_sorted=False)\n","    x, _ = self.lstm(x_pack)\n","    x, x_lens = pad_packed_sequence(x, batch_first=True)\n","    x = self.dense(x)\n","    x = self.logsoftmax(x)\n","    #Log_probs: Tensor of size (T, N, C)\n","    #T=input length, N = batch size C=number of classes\n","    x = x.permute(1, 0, 2) \n","    return x, x_lens"]},{"cell_type":"code","execution_count":null,"id":"96275796-387e-46ae-9e7d-d7f307423159","metadata":{"id":"96275796-387e-46ae-9e7d-d7f307423159"},"outputs":[],"source":["# create model\n","input_size = 40\n","hidden_size = 256\n","num_layers = 5\n","output_size = 42\n","\n","model = LSTMModel(input_size, hidden_size, num_layers, output_size)\n","model = model.to(device)\n","#print(model)"]},{"cell_type":"markdown","id":"hPGV78TVmcSC","metadata":{"id":"hPGV78TVmcSC"},"source":["The hyperparamerters here are almost the same as the [post ](https://piazza.com/class/knsmz2b3z131mn?cid=1448) suggested.\n"]},{"cell_type":"code","execution_count":null,"id":"068bf907-6d3c-4f10-abeb-356d42cf85f4","metadata":{"id":"068bf907-6d3c-4f10-abeb-356d42cf85f4"},"outputs":[],"source":["# Hyperparams\n","lr = 9e-3\n","weight_decay = 5e-6\n","criterion = nn.CTCLoss()\n","optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n","\n","# You can add a LR scheduler\n","scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.5, patience=3, cooldown=1, verbose=True)"]},{"cell_type":"code","execution_count":null,"id":"e1a24ecd-197f-4d49-99d9-518c7296549d","metadata":{"id":"e1a24ecd-197f-4d49-99d9-518c7296549d","outputId":"e52783eb-c98a-4364-8282-bea353ed3372"},"outputs":[{"name":"stderr","output_type":"stream","text":["Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mysie\u001b[0m (use `wandb login --relogin` to force relogin)\n"]},{"data":{"text/plain":["True"]},"execution_count":56,"metadata":{},"output_type":"execute_result"}],"source":["import wandb\n","wandb.login()"]},{"cell_type":"code","execution_count":null,"id":"89f5f2ad-3bfa-4f80-9926-5caedcf72651","metadata":{"id":"89f5f2ad-3bfa-4f80-9926-5caedcf72651","outputId":"e279a21e-8e6a-49af-d27c-e60b7d34a4d3"},"outputs":[{"data":{"text/html":["\n","                    Syncing run <strong><a href=\"https://wandb.ai/ysie/hw3/runs/150szepg\" target=\"_blank\">#9</a></strong> to <a href=\"https://wandb.ai/ysie/hw3\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n","\n","                "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["[]"]},"execution_count":57,"metadata":{},"output_type":"execute_result"}],"source":["# Initialize WandB \n","config = {\n","    'batch_size': batch_size,\n","    'learning_rate': lr,\n","    'conv1':'kernel_(1,1), stride = 1, padding = 0',\n","    'conv1':'kernel_(3,3), stride = 1, padding = 1',}\n","wandb.init(name='#9', \n","          project=\"hw3\",  \n","          config=config)\n","wandb.watch(model)"]},{"cell_type":"code","execution_count":null,"id":"82fa72ee-fd04-42b4-a0b3-4b459edcf824","metadata":{"id":"82fa72ee-fd04-42b4-a0b3-4b459edcf824"},"outputs":[],"source":["# Train the model\n","def train_epoch(model, train_loader, criterion, optimizer):\n","  model.train()\n","\n","  avg_loss = 0.0\n","  start = time.time()\n","\n","  # TODO: Add logic here\n","  for i, (x, y, x_lens, y_lens) in enumerate(train_loader):\n","    optimizer.zero_grad()    \n","    x, y, x_lens, y_lens = x.float().to(device), y.long().to(device), x_lens.to(device), y_lens.to(device)\n","    out, out_lens = model(x, x_lens)\n","    loss = criterion(out, y, out_lens, y_lens)\n","    loss.backward()\n","    optimizer.step()\n","    avg_loss += loss\n","    pbar.update(pbar_num)\n","    del out, out_lens, y, y_lens, x, x_lens\n","    gc.collect()\n","    torch.cuda.empty_cache()    \n","  end = time.time()\n","  avg_loss = avg_loss.item()/len(train_loader) # average batch loss\n","    \n","  print(f'Training loss: {avg_loss} Time: {end - start}')\n","  return avg_loss"]},{"cell_type":"code","execution_count":null,"id":"3059caae-54c8-4c5c-ae56-b092d262cd69","metadata":{"id":"3059caae-54c8-4c5c-ae56-b092d262cd69"},"outputs":[],"source":["import sys\n","sys.path.append(\"data/HW3P2_Data\")\n","\n","from phoneme_list import PHONEME_MAP, PHONEME_LIST"]},{"cell_type":"code","execution_count":null,"id":"01821170-8387-4093-a15f-531a9a59eb62","metadata":{"id":"01821170-8387-4093-a15f-531a9a59eb62"},"outputs":[],"source":["from ctcdecode import CTCBeamDecoder\n","\n","decoder = CTCBeamDecoder(\n","    PHONEME_MAP,\n","    model_path=None,\n","    alpha=0,\n","    beta=0,\n","    cutoff_top_n=42,\n","    cutoff_prob=1.0,\n","    beam_width=3,\n","    num_processes=num_workers,\n","    blank_id=0,\n","    log_probs_input=True\n",")\n"]},{"cell_type":"markdown","id":"xqHrORiAnbPb","metadata":{"id":"xqHrORiAnbPb"},"source":["Note: after getting output from the model, we need to permute the output because decoder.decode expects inputs with size (BATCHSIZE x N_TIMESTEPS x N_LABELS)"]},{"cell_type":"code","execution_count":null,"id":"c5e9444c-a6c2-4e05-96e4-d19992e0f143","metadata":{"id":"c5e9444c-a6c2-4e05-96e4-d19992e0f143"},"outputs":[],"source":["# Train the model\n","def validate_model(model, val_loader, criterion):\n","\n","  avg_loss = 0.0\n","  running_dist = 0.0\n","  distances = []\n","  with torch.no_grad():\n","    # model in validation mode \n","    model.eval()\n","\n","    start = time.time()\n","\n","    for i, (x, y, x_lens, y_lens) in enumerate(val_loader):\n","\n","      x, y, x_lens, y_lens = x.float().to(device), y.long().to(device), x_lens.to(device), y_lens.to(device)\n","      out, output_lens = model(x, x_lens)       \n","      loss = criterion(out, y, output_lens, y_lens)    \n","      avg_loss += loss\n","      \n","      out = out.permute(1, 0, 2) #BATCHSIZE x N_TIMESTEPS x N_LABELS for decoder.decode input\n","      #beam_results = n beams of a batch of items.Shape: batchsize x num_beams x num_timesteps\n","      #out_lens representing the length of each beam in beam_results.Shape: batchsize x n_beams.\n","      beam_results, beam_scores, timesteps, out_lens = decoder.decode(out, x_lens)\n","      predict = []\n","      for i in range(beam_results.size(0)):\n","        result =  beam_results[i, 0, :out_lens[i][0]] #always pick the top beam result\n","        phonemes_pred = \"\".join([PHONEME_MAP[j] for j in result])\n","        predict.append(phonemes_pred)\n","      label = []\n","      for i in range(y.size(0)):\n","        yy = y[i, :y_lens[i]]\n","        phonemes = \"\".join([PHONEME_MAP[j] for j in yy])\n","        label.append(phonemes)\n","      \n","      # Levenshtein\n","      for pred, target in zip(predict, label):\n","        distances.append(Levenshtein.distance(pred, target))      \n","      running_dist += np.mean(distances)\n","      pbar.update(pbar_num)\n","      del out, output_lens, y, y_lens, x, x_lens\n","      torch.cuda.empty_cache()\n","      gc.collect()\n","    end = time.time()\n","    avg_loss = avg_loss.item()/len(val_loader) \n","    running_dist /= len(val_loader)\n","    \n","    print(f'Validation loss: {avg_loss} Levenshtein distance: {running_dist} Time: {end - start}')    \n","    return avg_loss, distances, running_dist"]},{"cell_type":"code","execution_count":null,"id":"F1Kp1ZFSpV28","metadata":{"id":"F1Kp1ZFSpV28"},"outputs":[],"source":["start = 0\n","best_loss = float('inf')"]},{"cell_type":"markdown","id":"ZwgwrA9fnxj6","metadata":{"id":"ZwgwrA9fnxj6"},"source":["Don't run the following code until you get 0.34 validation loss. (It happens around 110~120th epoch in my case.) \n","\n","We will use that model to run the another 100 epochs with some adjustment on the optimizer and the scheduler first."]},{"cell_type":"code","execution_count":null,"id":"1e77b115-9068-4c15-9a58-85ed38bbdaec","metadata":{"id":"1e77b115-9068-4c15-9a58-85ed38bbdaec"},"outputs":[],"source":["start = 116"]},{"cell_type":"code","execution_count":null,"id":"47ed7be8-ffcb-4318-951b-cd9daa8d80a9","metadata":{"id":"47ed7be8-ffcb-4318-951b-cd9daa8d80a9"},"outputs":[],"source":["checkpoint = torch.load(\"path2/\"+str(start)+\".pth\")"]},{"cell_type":"code","execution_count":null,"id":"f1586f60-c1dc-4c3c-8773-54273043e976","metadata":{"id":"f1586f60-c1dc-4c3c-8773-54273043e976","outputId":"8b81f045-03b5-4be1-9e12-4f813e33783f"},"outputs":[{"name":"stdout","output_type":"stream","text":["Best validation loss:  0.34690017700195314\n"]}],"source":["model.load_state_dict(checkpoint['model_state_dict'])\n","optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n","print(\"Best validation loss: \", checkpoint['val_loss'])"]},{"cell_type":"code","execution_count":null,"id":"7674f0ff-7dc8-4932-aa0c-f4c0fd0bdc52","metadata":{"id":"7674f0ff-7dc8-4932-aa0c-f4c0fd0bdc52","outputId":"52f44964-fd57-4bd5-a295-33ca5deef759"},"outputs":[{"data":{"text/plain":["0.000140625"]},"execution_count":69,"metadata":{},"output_type":"execute_result"}],"source":["optimizer.param_groups[0]['lr']"]},{"cell_type":"markdown","id":"A93VdBldLG5P","metadata":{"id":"A93VdBldLG5P"},"source":["I noticed that when I got to 0.34 for validation loss after first 100ish epochs, the learning rate became really small, and it kept jumping aroud 0.34. \n","\n","Then, I tried going with the initial optimizer.(see the code below) It did give me some pretty bad validation loss in the beginning, but somehow once it went down to 0.34 again, the loss kept decreasing, and even gave me better result. (But it takes time)"]},{"cell_type":"code","execution_count":null,"id":"148ac53f-f127-4b59-8bee-46fe0c42d6b3","metadata":{"id":"148ac53f-f127-4b59-8bee-46fe0c42d6b3"},"outputs":[],"source":["optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n","scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.5, patience=2, verbose=True)\n","best_loss = checkpoint['val_loss']"]},{"cell_type":"markdown","id":"kp0nAP32oSd6","metadata":{"id":"kp0nAP32oSd6"},"source":["Please resume running the code here if the model haven't got to the 0.34 validation loss.\n","\n","\n","Once we get the 0.34 validation loss please stop running (ctrl+c) and run the cells above. (from top to down, we slightly adjusted the code to achieve lower validation loss) Once the scheduler and optimizer have been adjusted, please resume running the code below"]},{"cell_type":"code","execution_count":null,"id":"489af308-3cae-46a1-8f69-8d532ba0b399","metadata":{"colab":{"referenced_widgets":["a9c9a97477584dddb28df2950dd58c9e"]},"id":"489af308-3cae-46a1-8f69-8d532ba0b399","outputId":"9fc086b3-69e2-4611-ae98-f7286127499f"},"outputs":[{"name":"stdout","output_type":"stream","text":["Start...\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a9c9a97477584dddb28df2950dd58c9e","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/200 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch:  117\n"]}],"source":["# Define number of epochs\n","epochs = 200\n","\n","\n","print('Start...')\n","pbar_num = 1/(len(train_loader)+len(dev_loader))\n","with tqdm(total=epochs) as pbar:\n","    for epoch in range(start+1, start+epochs):\n","      print('Epoch: ', epoch)\n","\n","      training_loss = train_epoch(model, train_loader, criterion, optimizer)\n","      val_loss, distance, running_dist = validate_model(model, dev_loader, criterion)\n","\n","      # save the best model\n","      if val_loss < best_loss:\n","        print('>>>>>>>>>>>>>>>>>>Best loss: {}, epoch: {}'.format(val_loss, epoch))\n","        # TODO: Save model\n","        best_loss = val_loss\n","        torch.save({\n","        'epoch': epoch,\n","        'val_loss':val_loss,\n","        'model_state_dict': model.state_dict(),\n","        'optimizer_state_dict': optimizer.state_dict()}, 'path2/'+str(epoch)+'.pth')\n","      wandb.log({'Epoch' :  str(epoch), \n","                 'Train Loss' : training_loss,\n","                 'Val Loss' : val_loss, \n","                 'Distances': running_dist})\n","      scheduler.step(val_loss)\n","      torch.cuda.empty_cache()\n","      gc.collect()\n","      print('='*40)\n","print('Done...')"]},{"cell_type":"markdown","id":"y7XYK3pkphwy","metadata":{"id":"y7XYK3pkphwy"},"source":["Run the following code once we get a less-than-0.32 validation loss"]},{"cell_type":"code","execution_count":null,"id":"XLpgFI88p4_i","metadata":{"id":"XLpgFI88p4_i"},"outputs":[],"source":["best = #put the number with lowest validation loss\n","checkpoint = torch.load(\"path2/\"+str(best)+\".pth\")\n","model.load_state_dict(checkpoint['model_state_dict'])"]},{"cell_type":"code","execution_count":null,"id":"0140cba0-f572-4108-9fe0-0be531c29570","metadata":{"id":"0140cba0-f572-4108-9fe0-0be531c29570"},"outputs":[],"source":["# load test data\n","test_data = np.load('data/HW3P2_Data/test.npy', allow_pickle=True)"]},{"cell_type":"code","execution_count":null,"id":"7b382a36-990a-4fce-8c9c-d84927c866ab","metadata":{"id":"7b382a36-990a-4fce-8c9c-d84927c866ab"},"outputs":[],"source":["# Define dataset class\n","class TestDataSet(Dataset):\n","  # load the dataset\n","  def __init__(self, x):\n","    self.X = x\n","\n","  # get number of items/rows in dataset\n","  def __len__(self):\n","    return len(self.X) \n","\n","  # get row item at some index\n","  def __getitem__(self, index):\n","    x = torch.FloatTensor(self.X[index])\n","    return x\n","\n","  def collate_fn(batch):\n","    x_len = torch.as_tensor([len(x) for x in batch])\n","    x_pad = torch.as_tensor(pad_sequence(batch, batch_first=True)).permute(0, 2, 1)\n","    return x_pad, x_len"]},{"cell_type":"code","execution_count":null,"id":"c80aa85b-40d3-4309-b014-ae615240f97d","metadata":{"id":"c80aa85b-40d3-4309-b014-ae615240f97d"},"outputs":[],"source":["# test data\n","test = TestDataSet(test_data)\n","test_args = {'batch_size': batch_size, \n","            'shuffle': False, 'num_workers': num_workers, \n","            'collate_fn': TestDataSet.collate_fn, 'pin_memory': True}\n","test_loader = DataLoader(test, **test_args)"]},{"cell_type":"code","execution_count":null,"id":"ffd37e5c-da59-4a3a-b323-332aa9c5d49a","metadata":{"id":"ffd37e5c-da59-4a3a-b323-332aa9c5d49a"},"outputs":[],"source":["def test_model(model, test_loader):\n","  predict = []\n","  with torch.no_grad():\n","    # model in validation mode \n","    model.eval()\n","\n","    for i, (x, x_lens) in enumerate(test_loader):\n","\n","      x, x_lens = x.float().to(device), x_lens.to(device)\n","      out, _ = model(x, x_lens)             \n","      out = out.permute(1, 0, 2) #BATCHSIZE x N_TIMESTEPS x N_LABELS for decoder.decode input\n","      #beam_results = n beams of a batch of items.Shape: batchsize x num_beams x num_timesteps\n","      #out_lens representing the length of each beam in beam_results.Shape: batchsize x n_beams.\n","      beam_results, beam_scores, timesteps, out_lens = decoder.decode(out, x_lens)      \n","      for i in range(beam_results.size(0)):\n","        result =  beam_results[i, 0, :out_lens[i][0]] #always pick the top beam result\n","        phonemes_pred = \"\".join([PHONEME_MAP[j] for j in result])\n","        predict.append(phonemes_pred)\n","      \n","      del out, x, x_lens\n","      torch.cuda.empty_cache()\n","      gc.collect() \n","    return predict"]},{"cell_type":"code","execution_count":null,"id":"cfd18532-aba6-4bcf-be9e-5524b75adaad","metadata":{"id":"cfd18532-aba6-4bcf-be9e-5524b75adaad"},"outputs":[],"source":["predictions = test_model(model, test_loader)"]},{"cell_type":"code","execution_count":null,"id":"21beb02f-646b-46ea-9837-2e21d3d60784","metadata":{"id":"21beb02f-646b-46ea-9837-2e21d3d60784"},"outputs":[],"source":["#%%save prediction to csv\n","import pandas as pd\n","submit_verification = pd.read_csv(\"data/HW3P2_Data/sample_submission.csv\")"]},{"cell_type":"code","execution_count":null,"id":"b4072286-eabf-40c5-bb45-b0b1065fe932","metadata":{"id":"b4072286-eabf-40c5-bb45-b0b1065fe932"},"outputs":[],"source":["submit_verification['label']  = predictions"]},{"cell_type":"code","execution_count":null,"id":"9dca26f9-4db9-4ddf-b317-77eb87bbd609","metadata":{"id":"9dca26f9-4db9-4ddf-b317-77eb87bbd609"},"outputs":[],"source":["submit_verification.to_csv('Hw3.csv', index= False)"]},{"cell_type":"markdown","id":"gDom5fuFqNR6","metadata":{"id":"gDom5fuFqNR6"},"source":["Double check if we successfully write the result into the sample_submission.csv"]},{"cell_type":"code","execution_count":null,"id":"081030ad-9e61-4e94-95aa-d2f9e8158914","metadata":{"id":"081030ad-9e61-4e94-95aa-d2f9e8158914"},"outputs":[],"source":["(submit_verification['label']== predictions).all()"]},{"cell_type":"markdown","id":"6DJNc83hAjej","metadata":{"id":"6DJNc83hAjej"},"source":["Submit the results to Kaggle"]},{"cell_type":"code","execution_count":null,"id":"222329a4-5de8-4dc7-8ec2-6bb86cfa2bd1","metadata":{"id":"222329a4-5de8-4dc7-8ec2-6bb86cfa2bd1","outputId":"04fd107c-b910-4129-cd9b-a0f6a76f45f4"},"outputs":[{"name":"stdout","output_type":"stream","text":["100%|█████████████████████████████████████████| 305k/305k [00:00<00:00, 321kB/s]\n","Successfully submitted to 11785 Homework 3 Part 2 Slack: Seq to Seq"]}],"source":["!kaggle competitions submit -c 11785-homework-3-part-2-slack-seq-to-seq -f 'Hw3.csv' -m \"Message\""]}],"metadata":{"colab":{"collapsed_sections":[],"name":"hw3p2.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"}},"nbformat":4,"nbformat_minor":5}
